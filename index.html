<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>PAH: Prototype-Augmented Hypernetworks for Continual Learning</title>
  <link rel="stylesheet" href="./static/css/bulma.min.css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" />
  <link rel="stylesheet" href="./static/css/index.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css" />
  <meta name="description" content="Project page for 'Prototype-Augmented Hypernetworks for Continual Multitask Learning'" />
  <link rel="icon" href="./static/images/favicon.ico" type="image/x-icon" />
</head>

<body>
  <section class="hero">
    <div class="hero-body">
      <div class="container has-text-centered">
        <div style="display: flex; align-items: center; justify-content: center; gap: 20px; margin-top: 20px; flex-wrap: wrap;">
        <img src="./static/images/PAH_logo.png" alt="PAH Logo" style="width: 80px; height: auto;">
        <h3 class="title is-3 publication-title" style="margin: 0; max-width: 600px; text-align: left;">
          Prototype-Augmented Hypernetworks for Continual Multitask Learning
        </h3>
        </div>

        <br>
        <br>
        
        <div class="is-size-5 publication-authors" style="text-align: center; margin-bottom: 10px;">
          <div style="display: flex; justify-content: center; gap: 20px; flex-wrap: wrap;">
            <div class="author-block">Neil De La Fuente<sup>1,2*</sup></div>
            <div class="author-block">María Pilligua<sup>1*</sup></div>
            <div class="author-block">Daniel Vidal<sup>1</sup></div>
          </div>
          <div style="display: flex; justify-content: center; gap: 20px; flex-wrap: wrap; margin-top: 10px;">
            <div class="author-block">Albin Soutif<sup>1</sup></div>
            <div class="author-block">Cecilia Curreli<sup>2,3</sup></div>
            <div class="author-block">Daniel Cremers<sup>2,3</sup></div>
            <div class="author-block">Andrey Barsky<sup>1</sup></div>
          </div>
        </div>
        
        <div class="is-size-5 publication-authors" style="text-align: center; margin-top: 5px;">
          <span><sup>1</sup>Computer Vision Center</span> &nbsp;&nbsp;
          <span><sup>2</sup>TUM</span> &nbsp;&nbsp;
          <span><sup>3</sup>Munich Center for Machine Learning</span>
        </div>

        <br>
        <br>
        <br>
        
        <div class="column has-text-centered">
          <div class="publication-links">
            <span class="link-block">
              <a href="https://arxiv.org/abs/XXXX.XXXXX" class="external-link button is-normal is-rounded is-dark">
                <span class="icon"><i class="ai ai-arxiv"></i></span>
                <span>arXiv</span>
              </a>
            </span>
            <span class="link-block">
              <a href="https://github.com/pah2025/PAH" class="external-link button is-normal is-rounded is-dark">
                <span class="icon"><i class="fab fa-github"></i></span>
                <span>Code</span>
              </a>
            </span>
            <span class="link-block">
              <a href="https://www.latinxinai.org/" target="_blank" class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <img src="./static/images/LXAI_logo.png" 
                       alt="LXAI Logo" style="height: 1.2em;">
                </span>
                <span>LatinX in AI</span>
              </a>
            </span>
          </div>
        </div>
      </div>
    </div>
  </section>

  <div class="container">
    <p style="font-size: 1.5em; font-weight: bold; margin-top: 40px; margin-bottom: 20px;">Abstract</p>
    <p>
      Continual learning (CL) aims to learn a sequence of tasks without forgetting prior knowledge, but gradient updates for a new task often overwrite the weights learned earlier, causing catastrophic forgetting (CF). We propose Prototype-Augmented Hypernetworks (PAH), a framework where a single hypernetwork, conditioned on learnable task prototypes, dynamically generates task-specific classifier heads on demand. To mitigate forgetting, PAH combines cross-entropy with dual distillation losses, one to align logits and another to align prototypes, ensuring stable feature representations across tasks. Evaluations on Split-CIFAR100 and TinyImageNet demonstrate that PAH achieves state-of-the-art performance, reaching 74.5% and 63.7% accuracy with only 1.7% and 4.4% forgetting, respectively, surpassing prior methods without storing samples or heads.
    </p>

    <p style="font-size: 1.5em; font-weight: bold; margin-top: 40px; margin-bottom: 20px;">Model Architecture</p>
    <img src="./static/images/arch_PAH.png" alt="PAH Architecture" style="width: 80%; display: block; margin: 20px auto;">

    <p style="font-size: 1.5em; font-weight: bold; margin-top: 40px; margin-bottom: 20px;">Learnable Task Prototypes</p>
    <p>
      In PAH, each task is represented by a learnable task prototype that encodes semantic and spatial information about the task’s classes. These prototypes are 2D feature grids (e.g., 10×10), initialized from resized training samples and optimized throughout training. They are not used for classification directly, but instead condition the hypernetwork to dynamically generate classifier heads.
    </p>
    <p>
      The task prototype for a given task is formed by concatenating the class prototypes and flattening them into a vector. This vector is then fed into the hypernetwork, which outputs the weights for the classifier head corresponding to that task. Prototypes are updated using KL-divergence losses to remain aligned with the evolving feature space.
    </p>
    
    <p>
      The figure below illustrates how prototypes encode each task and influence classifier generation:
    </p>
    <img src="./static/images/prototype_generation.png" alt="Prototype Learning Diagram" style="width: 80%; display: block; margin: 20px auto;">


    <p style="font-size: 1.5em; font-weight: bold; margin-top: 40px; margin-bottom: 20px;">Installation</p>
    <pre><code>git clone https://github.com/pah2025/PAH
cd PAH
python -m venv env
source env/bin/activate  # Or env\\Scripts\\activate on Windows
pip install -r requirements.txt
</code></pre>

    <p style="font-size: 1.5em; font-weight: bold; margin-top: 40px; margin-bottom: 20px;">Usage</p>
    <p>Modify <code>config/hyper2d.py</code> with your desired parameters and then run:</p>
    <pre><code>python train_hyper2d.py config/hyper2d.py</code></pre>

    <p style="font-size: 1.5em; font-weight: bold; margin-top: 40px; margin-bottom: 20px;">Data</p>
    <p>
      The script will download and save Split-MNIST and Split-CIFAR100 in the <code>data/</code> folder.
      You can download TinyImageNet from <a href="https://paperswithcode.com/dataset/tiny-imagenet" target="_blank">here</a>.
    </p>

    <p style="font-size: 1.5em; font-weight: bold; margin-top: 40px; margin-bottom: 20px;">Results</p>
    <p>Training results are saved in the <code>results/</code> directory and optionally visualized with Weights & Biases.</p>

    <hr style="margin: 40px 0;">
    <footer style="font-size: 12px; text-align: center;">
      Template inspired by <a href="https://hypernvd.github.io" target="_blank">HyperNVD</a>
    </footer>
  </div>
</body>
</html>
