<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>PAH: Prototype-Augmented Hypernetworks for Continual Learning</title>
  <link rel="stylesheet" href="./static/css/bulma.min.css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" />
  <link rel="stylesheet" href="./static/css/index.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css" />
  <meta name="description" content="Project page for 'Prototype-Augmented Hypernetworks for Continual Multitask Learning'" />
  <link rel="icon" href="./static/images/architecture.png" type="image/x-icon" />
</head>

<body>
  <section class="hero">
    <div class="hero-body">
      <div class="container has-text-centered">
        <img src="./static/images/architecture.png" alt="PAH Logo" style="width: 450px; height: auto; margin-top: 20px;">
        <h3 class="title is-3 publication-title">Prototype-Augmented Hypernetworks for Continual Multitask Learning</h3>

        <div class="is-size-5 publication-authors" style="text-align: center; margin-bottom: 10px;">
          <div style="display: flex; justify-content: center; gap: 20px; flex-wrap: wrap;">
            <div class="author-block">Neil De La Fuente<sup>1,2*</sup></div>
            <div class="author-block">Mar√≠a Pilligua<sup>1*</sup></div>
            <div class="author-block">Daniel Vidal<sup>1</sup></div>
          </div>
          <div style="display: flex; justify-content: center; gap: 20px; flex-wrap: wrap; margin-top: 10px;">
            <div class="author-block">Albin Soutif<sup>1</sup></div>
            <div class="author-block">Andrey Barsky<sup>1</sup></div>
            <div class="author-block">Cecilia Curreli<sup>2,3</sup></div>
            <div class="author-block">Daniel Cremers<sup>2,3</sup></div>
          </div>
        </div>
        
        <div class="is-size-5 publication-authors" style="text-align: center; margin-top: 5px;">
          <span><sup>1</sup>Computer Vision Center</span> &nbsp;&nbsp;
          <span><sup>2</sup>TUM</span> &nbsp;&nbsp;
          <span><sup>3</sup>Munich Center for Machine Learning</span>
        </div>


        <div class="column has-text-centered">
          <div class="publication-links">
            <span class="link-block">
              <a href="https://arxiv.org/abs/XXXX.XXXXX" class="external-link button is-normal is-rounded is-dark">
                <span class="icon"><i class="ai ai-arxiv"></i></span>
                <span>arXiv</span>
              </a>
            </span>
            <span class="link-block">
              <a href="https://github.com/pah2025/PAH" class="external-link button is-normal is-rounded is-dark">
                <span class="icon"><i class="fab fa-github"></i></span>
                <span>Code</span>
              </a>
            </span>
            <span class="link-block">
              <a href="https://www.latinxinai.org/" target="_blank" class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/9/9c/LXAI_Logo_Black.png/320px-LXAI_Logo_Black.png" 
                       alt="LXAI Logo" style="height: 1.2em;">
                </span>
                <span>LatinX in AI</span>
              </a>
            </span>
          </div>
        </div>
      </div>
    </div>
  </section>

  <div class="container">
    <p style="padding-top: 30px; padding-bottom:15px; text-align: left;"><strong>Abstract</strong></p>
    <p>
      Continual learning (CL) aims to learn a sequence of tasks
      without forgetting prior knowledge, but gradient updates
      for a new task often overwrite the weights learned earlier,
      causing catastrophic forgetting (CF). We propose Prototype-
      Augmented Hypernetworks (PAH), a framework where a
      single hypernetwork, conditioned on learnable task proto-
      types, dynamically generates task-specific classifier heads
      on demand. To mitigate forgetting, P AH combines cross-
      entropy with dual distillation losses, one to align logits and
      another to align prototypes, ensuring stable feature repre-
      sentations across tasks. Evaluations on Split-CIFAR100
      and TinyImageNet demonstrate that PAH achieves state-of-
      the-art performance, reaching 74.5% and 63.7% accuracy
      with only 1.7% and 4.4% forgetting, respectively, surpassing
      prior methods without storing samples or heads.
    </p>

    <p style="padding-top: 30px;"><strong>Model Architecture</strong></p>
    <img src="./static/images/architecture.png" alt="PAH Architecture" style="width: 80%; display: block; margin: 20px auto;">

    <p style="padding-top: 30px;"><strong>Installation</strong></p>
    <pre><code>git clone https://github.com/pah2025/PAH
cd PAH
python -m venv env
source env/bin/activate  # Or env\\Scripts\\activate on Windows
pip install -r requirements.txt
</code></pre>

    <p style="padding-top: 30px;"><strong>Usage</strong></p>
    <p>Modify <code>config/hyper2d.py</code> with your desired parameters and then run:</p>
    <pre><code>python train_hyper2d.py config/hyper2d.py</code></pre>

    <p style="padding-top: 30px;"><strong>Data</strong></p>
    <p>
      The script will download and save Split-MNIST and Split-CIFAR100 in the <code>data/</code> folder.
      You can download TinyImageNet from <a href="https://paperswithcode.com/dataset/tiny-imagenet" target="_blank">here</a>.
    </p>

    <p style="padding-top: 30px;"><strong>Results</strong></p>
    <p>Training results are saved in the <code>results/</code> directory and optionally visualized with Weights & Biases.</p>

    <hr style="margin: 40px 0;">
    <footer style="font-size: 12px; text-align: center;">
      Template inspired by <a href="https://hypernvd.github.io" target="_blank">HyperNVD</a>
    </footer>
  </div>
</body>
</html>
